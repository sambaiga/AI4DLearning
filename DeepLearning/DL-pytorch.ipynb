{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch for Deeplearning Research and Development\n",
    "\n",
    "**Authors:** Faustine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "###  What is Pytorch\n",
    "[PyTorch](http://pytorch.org/) is an open source deep learning framework that two high-level features: Tensor computation (like numpy) with strong GPU acceleration and Deep Neural Networks built on a tape-based autograd system. \n",
    "\n",
    "\n",
    "This  notebook require PyTorch 1.8.0 or later. You can check the version number of the currently installed pytorch package with:  ```python print(torch.__version__)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tensors\n",
    "\n",
    "The main building block of the PyTorch is the tensors. **Tensor** is a multi-dimensional matrix containing elements of a single data type. They are very similar to the NumPy array. However, unlike numpy array, pytorch tensor can utilize GPU. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don‚Äôt need it too often\n",
    "\n",
    " A tensor can be constructed from a Python list or sequence with the [**torch.Tensor()**](https://pytorch.org/docs/stable/tensors.html) function.  The simplest approach for creating tensor is to call torch.Tensor passing the desired shape as input argument:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00, -3.6893e+19,  4.9934e+10],\n",
      "         [-1.5849e+29,  8.4078e-45,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "#Create a torch.Tensor object with the given data.  It is a 1D vector\n",
    "x = torch.Tensor(1, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Creates a matrix\n",
    "data = [[1., 2., 3.], [4., 5., 6]]\n",
    "M = torch.Tensor(data)\n",
    "print (M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can create a tensor with *random data* and the supplied dimensionality with **torch.randn()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8927, -1.1887,  0.8313, -1.1393],\n",
      "         [-0.1755, -0.5165, -0.0886, -0.0924]]])\n"
     ]
    }
   ],
   "source": [
    "# Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "x = torch.randn(1, 2, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9265, 0.2729, 0.2896, 0.0472, 0.8927],\n",
       "        [0.6750, 0.3390, 0.1165, 0.7170, 0.6416]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "torch.rand(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use special tensors line ones and zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get size of tensor you can use **.size()**, it also possible to use **.shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To returns the value of this tensor as a standard Python number use **.item()**. This only works for tensors with one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9302)\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302080273628235\n"
     ]
    }
   ],
   "source": [
    "print(x[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy  to Tensor Conversion\n",
    "   \n",
    "You can easily convernt pytorh tensor into numpy array and viceversa.  To create a tensor from a Numpy array, use `torch.from_numpy()` or `torch.Tensor()`. To convert a tensor to a Numpy array, use the `.numpy()` method. In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like ``np_arr = tensor.cpu().numpy().``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06472947  1.70402077  0.02912659 -1.19314253]\n",
      " [-0.03120482 -0.87608583 -1.12750342  1.06903766]\n",
      " [ 0.7236636  -0.08424339 -0.95457801 -0.2746394 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_arr = np.random.randn(3, 4)\n",
    "print(numpy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0647,  1.7040,  0.0291, -1.1931],\n",
      "        [-0.0312, -0.8761, -1.1275,  1.0690],\n",
      "        [ 0.7237, -0.0842, -0.9546, -0.2746]])\n"
     ]
    }
   ],
   "source": [
    "# convert numpy array to pytorch array\n",
    "pytorch_tensor = torch.Tensor(numpy_arr)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0647,  1.7040,  0.0291, -1.1931],\n",
      "        [-0.0312, -0.8761, -1.1275,  1.0690],\n",
      "        [ 0.7237, -0.0842, -0.9546, -0.2746]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# use from_numpy\n",
    "pytorch_tensor = torch.from_numpy(numpy_arr)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06472947,  1.70402077,  0.02912659, -1.19314253],\n",
       "       [-0.03120482, -0.87608583, -1.12750342,  1.06903766],\n",
       "       [ 0.7236636 , -0.08424339, -0.95457801, -0.2746394 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert torch tensor to numpy representation\n",
    "pytorch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations \n",
    "\n",
    "You can operate on tensors in the ways you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x + y\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "# You can also use\n",
    "z = torch.add(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling x1 + x2 creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of x2 without the chance to re-accessing the values of x2 before the operation. In-place operations are usually marked with a underscore postfix (e.g. ‚Äúadd_‚Äù instead of ‚Äúadd‚Äù).\n",
    "\n",
    "An example is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (before) tensor([1., 2., 3.])\n",
      "x (after) tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(\"x (before)\", x)\n",
    "\n",
    "x.add_(y)\n",
    "print(\"x (after)\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other commonly used operations include matrix multiplications.\n",
    "\n",
    "- `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the documentation). Can also be written as a @ b, similar to numpy.\n",
    "\n",
    "- `torch.mm`: Performs the matrix product over two matrices, but doesn‚Äôt support broadcasting.\n",
    "\n",
    "- `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor ùëá is of shape `(ùëè√óùëõ√óùëö)`, and the second tensor `ùëÖ (ùëè√óùëö√óùëù)`, the output ùëÇ is of shape `(ùëè√óùëõ√óùëù)`, and has been calculated by performing ùëè matrix multiplications of the submatrices of ùëá and `ùëÖ: ùëÇùëñ=ùëáùëñ@ùëÖùëñ`\n",
    "\n",
    "- `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more and compresnive list on pytorch  operations follow [pytorch documentation](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensors\n",
    "\n",
    "The **.view()** method  provide a function to reshape a tensor. This method receives heavy use, because many neural network components expect their inputs to have a certain shape. Often you will need to reshape before passing your data to the component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8449, -0.2398,  1.1446, -0.1973],\n",
       "         [-0.6589,  0.0639,  0.8396,  0.7696],\n",
       "         [ 1.2375, -0.4809, -0.4734, -0.8645]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8449, -0.2398,  1.1446, -0.1973, -0.6589,  0.0639,  0.8396,  0.7696,\n",
       "          1.2375, -0.4809, -0.4734, -0.8645]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to 1 rows, 12 columns\n",
    "x.view(1, 12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8449, -0.2398],\n",
       "         [ 1.1446, -0.1973],\n",
       "         [-0.6589,  0.0639],\n",
       "         [ 0.8396,  0.7696],\n",
       "         [ 1.2375, -0.4809],\n",
       "         [-0.4734, -0.8645]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to 1x6x2 \n",
    "x.reshape(1, 6, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Torch indexing operations](https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support\n",
    "Pytorch has GPU support that  greatly speed up training of deep learning  models by running the matrix operations on a GPU with CUDA. GPU support is implemented in `torch.cuda`. This package adds support for CUDA tensor types, that implement the same function as CPU tensors, but they utilize GPUs for computation. The new API (v0.4.0) lets us define it in a nice way.\n",
    "\n",
    "You can use `is_available()` to determine if your system supports CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuda support\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA supported\")\n",
    "    \n",
    "else:\n",
    "    print(\"No cuda support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors between  CPU and  GPU\n",
    "\n",
    "A torch.device contains a device type ('cpu' or 'cuda') and optional device ordinal (id) for the device type. It can be initilized with torch.device('{device_type}'). \n",
    "\n",
    "- The device attribute of a Tensor gives the torch.device for all Tensors (get_device only works for CUDA tensors)\n",
    "- The to method of Tensors and Modules can be used to easily move objects to different devices (instead of having to call cpu() or cuda() based on the context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device type set: CPU\n"
     ]
    }
   ],
   "source": [
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device type set:\", \"GPU\" if device.type == \"cuda\" else \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can be moved onto any device using the **.to** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convernt tensor into device\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "You can access use PyTorch with GPU in [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true). Details on how to get started can be found [here](https://jovianlin.io/pytorch-with-gpu-in-google-colab/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd and Variables \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autograd** provide a mechanism to compute error gradients and back-propagated through the computational graph. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "**torch.Tensor** is the central class of the package. If you set its attribute **.requires_grad** as True, it starts to track all operations on it. When you finish your computation you can call **.backward()** and have all the gradients computed automatically. \n",
    "\n",
    "To stop a tensor from tracking history, you can call **.detach()** to detach it from the computation history, and to prevent future computation from being tracked.\n",
    "\n",
    "To prevent tracking history (and using memory), you can also wrap the code block in **with torch.no_grad()**:. This is  helpful when evaluating a model because the model may have trainable parameters with requires_grad=True, but for which we don‚Äôt need the gradients.\n",
    "\n",
    "\n",
    "Every tensor instance has two attributes: **.data** that contain initial tensor itself and **.grad** that will contain gradients for the corresponding tensor. \n",
    "### NOTE:\n",
    "**Computation graph** is simply a specification of how your data is combined to give you the output. Since the graph totally specifies what parameters were involved with which operations, it contains enough information to compute derivatives. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: if we have $y = wx + b$ it clear that $\\frac{\\partial y}{\\partial x} =w$, $\\frac{\\partial y}{\\partial b} = 1$ and $\\frac{\\partial y}{\\partial w} = x$\n",
    "\n",
    "\n",
    "To compute the derivatives, you can call **.backward()** on a Variable. If Variable is a scalar (i.e. it holds a one element tensor), you don‚Äôt need to specify any arguments to backward(), however if it has more elements, you need to specify a grad_output argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0,  requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18.]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors variables.\n",
    "x = torch.ones((1, 1), requires_grad=True) \n",
    "\n",
    "# perform operations\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "\n",
    "# find gradient\n",
    "z.backward()\n",
    "\n",
    "#print gradient\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of x is equal to 18. This is equivalent to:\n",
    "$$\n",
    "z = 3y^2 \\text{ where } y = x + 2 \\Rightarrow z = 3(x + 2)^2\n",
    "$$\n",
    "\n",
    "Thus: $$ \\frac{dz}{dx} = 6(x +2) = 6(1+2) = 18$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Building Blocks\n",
    "\n",
    "Deep learning consists of composing linearities with non-linearities modules. The introduction of non-linearities allows for powerful models. Given linear and non-liear module how to define objective function and train deep learninh model in pytorch.\n",
    "\n",
    "Neural networks can be constructed using the **torch.nn** package. It provides pretty much all neural network related functionalities such as :\n",
    "\n",
    "- Linear layers - nn.Linear, nn.Bilinear\n",
    "- Convolution Layers - nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.ConvTranspose2d\n",
    "- Nonlinearities - nn.Sigmoid, nn.Tanh, nn.ReLU, nn.LeakyReLU\n",
    "- Pooling Layers - nn.MaxPool1d, nn.AveragePool2d\n",
    "- Recurrent Networks - nn.LSTM, nn.GRU\n",
    "- Normalization - nn.BatchNorm2d\n",
    "- Dropout - nn.Dropout, nn.Dropout2d\n",
    "- Embedding - nn.Embedding\n",
    "- Loss Functions - nn.MSELoss, nn.CrossEntropyLoss, nn.NLLLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above **torch.nn** classes requires defining an instance of the class and then running inputs through the instance.\n",
    "\n",
    "Pytorch provide the functional API thta allows users to  use these classes in a functional way. Such as\n",
    "\n",
    "`import torch.nn.functional as F`\n",
    "\n",
    "- Linear layers - F.linear(input=x, weight=W, bias=b)\n",
    "- Convolution Layers - F.conv2d(input=x, weight=W, bias=b, stride=1, padding=0, dilation=1, groups=1)\n",
    "- Nonlinearities - F.sigmoid(x), F.tanh(x), F.relu(x), F.softmax(x)\n",
    "- Dropout - F.dropout(x, p=0.5, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Linear function (Affine Maps)\n",
    "\n",
    "This is the core building block of deep learning defined is a function:\n",
    "$$ f(x) = \\mathbf{wx + b}$$ for a matrix $\\mathbf{w} $ and vectors $\\mathbf{x,b}$. Linear function is implemented in: torch.nn\n",
    "\n",
    "**torch.nn.Linear(in_features, out_features, bias=True)**\n",
    "\n",
    "\n",
    "Note: pytorch maps the rows of the input instead of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(1, 1, bias=True)\n",
    "x = torch.Tensor(np.arange(-50, 50).reshape(-1,1))\n",
    "y = lin(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,2))\n",
    "plt.plot(x.data.numpy(), y.data.numpy(), label=\"linear\")\n",
    "plt.title(\"Linear Activation\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linearities Function (Activation Function)\n",
    "\n",
    "Most used non-linear functions are: sigmoid, tanh and relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## sigmoid\n",
    "y = torch.sigmoid(x)\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,2))\n",
    "plt.plot(x.data.numpy(), y.data.numpy(), label=\"sigmoid\")\n",
    "plt.title(\"Sigmoid Activation\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Relu\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,2))\n",
    "y = F.relu(x)\n",
    "plt.plot(x.data.numpy(), y.data.numpy(), label=\"ReLU\")\n",
    "plt.title(\"ReLU Activation\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Relu\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,2))\n",
    "y = torch.tanh(x)\n",
    "plt.plot(x.data.numpy(), y.data.numpy(), label=\"Tanh\")\n",
    "plt.title(\"Tanh Activation\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other pytorch modules for defining neural networks\n",
    "\n",
    "`torch.optim`: provides implementations of standard stochastic optimization techniques.\n",
    "\n",
    "`torch.distributions`: contains parameterizable probability distributions and sampling functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating a neural network\n",
    "\n",
    "To create a neural network in PyTorch, we use **nn.Module** base class with Python class inheritance which allows us to use all of the functionality of the **nn.Module base class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nb_feature, nb_output):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(nb_feature, hidden_size) \n",
    "        self.fc2 = torch.nn.Linear(hidden_size, nb_output)  \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the class definition, you can see the inheritance of the base class **torch.nn.Module**. \n",
    "- Then, in the first line of the class initialization (def __init__(self):) we have the required Python **super() function**, which creates an instance of the base **torch.nn.Module** class. \n",
    "- The next line define a linear object defined by **torch.nn.Linear**, with the first argument in the definition being the number of input feature and the next argument being the number of output.\n",
    "- After that we need to define how data flows through out network. This can be doe using **forward()** method in which we supply the input data x as the primary argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch** offers an alternative easier and  more convenient way of creating neural networ using `torch.nn.Sequential` class. You can also define your own layers  and add them to the Sequential chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_feature = 2\n",
    "hidden_size = 10\n",
    "nb_output = 1\n",
    "model_type_2 = torch.nn.Sequential(torch.nn.Linear(nb_feature, hidden_size),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(hidden_size, nb_output)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an instance of this network architecture and assign this instance to cuda() method if available. Suppose we have the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = torch.randn(10, 8)\n",
    "y = torch.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(8, 1)\n",
    "#move to device\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the instance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc1): Linear(in_features=8, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "To train this model we need to setup an optimizer and a loss criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first line, we create a stochastic gradient descent optimizer, and we specify the learning rate and supply the model parameters using **model.parameters()** method of the base **torch.nn.Module** class that we inherit.\n",
    "- Next, we set our loss criterion to be the **MSE** loss. For details on different loss function you may refer to [pytorch documentation](http://pytorch.org/docs/master/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the training process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we run optimizer.zero_grad() ‚Äì this zeroes / resets all the gradients in the model, so that it is ready to go for the next back propagation pass. In other libraries this is performed implicitly, but in PyTorch you have to remember to do it explicitly.\n",
    "- Then we we pass the input data into the model **pred = model(x)** ‚Äì this will call the **forward()** method in our model class.\n",
    "- After that we get the MSE loss between the output of our network and the target data as **loss = criterion(y_pred, y_data)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.4534808099269867\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "pred = model(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we runs a back-propagation operation from the loss Variable backwards through the network using **loss.backward()***\n",
    "- Finaly we tell PyTorch to execute a gradient descent step based on the gradients calculated during the **.backward()** operation using **optimizer.step()**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data loaders\n",
    "\n",
    "PyTorch provides two classess the **Dataset class and the Dataloader class** that can be used to to feed  training data into the network.\n",
    "\n",
    "**Dataset class** is used to provide an interface for accessing all the training or testing samples in your dataset. To achieve this, you have to implement two method, `__getitem__` and `__len__` so that each training sample  can be accessed by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    \"\"\" custom dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        x = (x - x.mean(axis=0))/(x.std(axis=0))\n",
    "        \n",
    "        self.len = x.shape[0]\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pima/diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0fb4108eddae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Let us prepare data and define the dataset class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/pima/diabetes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/pima/diabetes.csv'"
     ]
    }
   ],
   "source": [
    "## Let us prepare data and define the dataset class\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/pima/diabetes.csv\")\n",
    "\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target = ['Outcome']\n",
    "\n",
    "inputs = df[features].as_matrix()\n",
    "targets = df[target].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = customDataset(x=inputs, y=targets)\n",
    "\n",
    "#print length of the datasets\n",
    "print(dataset.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Dataloader class** accept a dataset and other parameters such as **batch size** etc to load the data and so Then we can iterate over the Dataloader to get batches of training data and train your models. This class provides several important functionality for building deep learning models such as batching, shuffling, multiprocess data loading, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To access data in data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data=next(iter(data_loader))\n",
    "X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iterate through our data we use for loop as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training purpose will \n",
    "for i, (x_data, y_data) in enumerate(data_loader, 0):\n",
    "         if i ==2:\n",
    "            print(x_data)\n",
    "            print(y_data)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn,  device, data_loader, num_epochs, print_every=2):\n",
    "    \n",
    "    total_loss = []\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Start training\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        training_loss = []\n",
    "        \n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "        \n",
    "            # Calculate Loss: \n",
    "            loss = loss_fn(pred, targets)\n",
    "            training_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        total_loss.append(np.mean(training_loss))\n",
    "        if epoch % print_every == 0:\n",
    "          print('Train Epoch: {} [{}/{} ({:.0f}%)]  Loss: {:.6f}'.format(\n",
    "                epoch+1, i * len(inputs), len(data_loader.dataset),\n",
    "                100. * i / len(data_loader), np.mean(training_loss)))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = train(model, optimizer, criterion, device, data_loader, 1000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- [Adventures in machine learning](http://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/)\n",
    "- [DeepLearningZeroToAll](https://github.com/hunkim/DeepLearningZeroToAll)\n",
    "- [MILA welocome tutorial](https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch)\n",
    "- [PyTorch With Baby Steps: From y = x To Training A Convnet](http://lelon.io/blog/2018/02/08/pytorch-with-baby-steps)\n",
    "- [How to Use Your Own Custom Dataset for Classification in PyTorch](https://jdhao.github.io/2017/10/23/pytorch-load-data-and-make-batch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"myfootnote1\">1</a>: http://pytorch.org/about/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
