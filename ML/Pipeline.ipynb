{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build a Machine Learning model to predict if a given adult's yearly income is above or below $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/income_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Missing values in the dataset \n",
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum().sort_values(ascending = False)/len(df)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=df.isnull().sum().sort_values(ascending = False)\n",
    "percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100, 2)\n",
    "pd.concat([total, percent], axis = 1,keys= ['Total', 'Percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  2. Visualize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax = df.income_status.value_counts().plot(kind='bar')\n",
    "ax.set_title(\"Income status \\n (0 < 50K, 1 >50K)\")\n",
    "ax.set_ylabel(\"Counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Gender and income\n",
    "ax = sns.countplot(x = \"sex\", \n",
    "                   hue=\"income_status\",\n",
    "                   data = df, \n",
    "                   linewidth=2\n",
    ")\n",
    "plt.title(\"Income status vs Sex \\n (0 < 50K, 1 >50K)\")\n",
    "plt.ylabel(\" No of Patients\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = \"workclass\", \n",
    "                   hue=\"income_status\",\n",
    "                   data = df, \n",
    "                   linewidth=2\n",
    ")\n",
    "plt.title(\"Income status vs workclass \\n (0 < 50K, 1 >50K)\")\n",
    "plt.ylabel(\" No of Patients\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = \"marital-status\", \n",
    "                   hue=\"income_status\",\n",
    "                   data = df, \n",
    "                   linewidth=2\n",
    ")\n",
    "plt.title(\"Income status vs marital-status \\n (0 < 50K, 1 >50K)\")\n",
    "plt.ylabel(\"No of Patients\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column = \"age\"\n",
    "ax=sns.kdeplot(df.loc[(df['income_status'] == 0),column] , color='gray' ,shade=True,label='$<50K$')\n",
    "ax=sns.kdeplot(df.loc[(df['income_status']  == 1),column] , color='g',shade=True, label='$>50K$')\n",
    "plt.title('Age distribution:1 vs 0')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build data-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create train and test set\n",
    "y=df['income_status']\n",
    "X = df.drop(['income_status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X.sample(frac=0.85,random_state=200)\n",
    "X_test=X.drop(X_train.index)\n",
    "y_train = y.loc[X_train.index]\n",
    "y_test  = y.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax = y_test.value_counts().plot(kind='bar')\n",
    "ax.set_title(\"Test Income status \\n (0 < 50K, 1 >50K)\")\n",
    "ax.set_ylabel(\"Counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check data distribution\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax = y_train.value_counts().plot(kind='bar')\n",
    "ax.set_title(\"Train Income status \\n (0 < 50K, 1 >50K)\")\n",
    "ax.set_ylabel(\"Counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_column=[\"native-country\", \"workclass\", \"education\", \"marital-status\", \"race\" ,\n",
    "              \"occupation\", \"relationship\"]\n",
    "numeric_column=[\"age\", \"education-num\", 'fnlwgt', 'capital-gain', \"capital-loss\", \"hours-per-week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(numeric_feature, categorical_feature):\n",
    "       \n",
    "    numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                            ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                            ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_feature),\n",
    "                     ('cat', categorical_transformer, categorical_feature)])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pipeline=data_pipeline(numeric_column, categ_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4. Build and train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', df_pipeline), ('classifier', lg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test  = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train.values, y_pred_train)\n",
    "cm_test = confusion_matrix(y_test.values, y_pred_test)\n",
    "\n",
    "f_1_tra = f1_score(y_true=y_train.values, y_pred=y_pred_train)\n",
    "f_1_test = f1_score(y_true=y_test.values, y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train score:{f_1_tra}: Test score:{f_1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train cm:\\n {cm_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Test cm:\\n {cm_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 6. Cross validation and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"LG\":LogisticRegression(),\n",
    "          \"RF\":RandomForestClassifier(n_estimators=100),\n",
    "          \"GB\":GradientBoostingClassifier(n_estimators=100),\n",
    "          \"DT\":DecisionTreeClassifier()\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_best_model(X, y, models, data_pipeline,  score='f1', cv=3):\n",
    "    \n",
    "    mean_score = {}\n",
    "    std_score  = {}\n",
    "    model_time = {}\n",
    "    \n",
    "    skfold = model_selection.StratifiedKFold(n_splits=cv)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(\"fit {} model\".format(model_name))\n",
    "        clf = Pipeline(steps=[('preprocessor', data_pipeline),('classifier', model)])\n",
    "        start = time()\n",
    "        cv_results = model_selection.cross_val_score(clf, X, y, cv=skfold, scoring=score)\n",
    "        end = time()\n",
    "        mean_score[model_name] = cv_results.mean()\n",
    "        std_score[model_name]  =  cv_results.std()\n",
    "        model_time[model_name] = end - start\n",
    "        \n",
    "        print(\"{0}:score: {1:.3f}+-{2:.3f}:time {3:.3f}\".format(model_name,mean_score[model_name],\n",
    "                                            std_score[model_name], model_time[model_name]  ))\n",
    "    return mean_score, std_score, model_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_score, std_score, model_time  = find_best_model(X_train, y_train, models, df_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plotbar(plot_name, names, result,title,ylabel):\n",
    "    postion = np.arange(len(names))\n",
    "    plt.bar(postion, result, align='center', color ='g')\n",
    "    plt.axhline(0.65, color=\"r\", lw=1)\n",
    "    plt.xticks(postion, names, rotation=90)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotbar(\"cv_score\", list(models.keys()), list(mean_score.values()), \"F-1 Score Performance\", \"F-Score \\n (Higher is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_parameters = {\"classifier__C\":np.logspace(0, 4, 10),\n",
    "                \"classifier__penalty\": ['l1', 'l2']\n",
    "}\n",
    "\n",
    "gb_parameters = {\n",
    "    \"classifier__loss\":[\"deviance\"],\n",
    "    \"classifier__learning_rate\": [0.01, 0.025, 0.075, 0.1],\n",
    "    \"classifier__max_depth\":[3,5,8],\n",
    "    \"classifier__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"classifier__n_estimators\":[10, 100]\n",
    "    }\n",
    "\n",
    "parameters = {\"LG\": lg_parameters, \"GB\": gb_parameters}\n",
    "models = {\n",
    "          \"LG\":LogisticRegression(),\n",
    "          \"GB\":GradientBoostingClassifier(),\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def parameters_search(X_train, y_train, X_test, y_test,  models, parameters, data_pipeline,  score='f1', cv=3):\n",
    "    \n",
    "    tra_score = {}\n",
    "    test_score = {}\n",
    "    best_parameters = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(\"fit {} model\".format(model_name))\n",
    "        clf = Pipeline(steps=[('preprocessor', data_pipeline),('classifier', model)])\n",
    "        clfs = GridSearchCV(clf, parameters[model_name], cv=cv, scoring='f1_micro')\n",
    "        clfs.fit(X_train, y_train)\n",
    "        be = clfs.best_estimator_\n",
    "        y_pred_train = be.predict(X_train)\n",
    "        y_pred_test  = be.predict(X_test)\n",
    "        tra_score[model_name] = f1_score(y_true=y_train.values, y_pred=y_pred_train)\n",
    "        test_score[model_name] = f1_score(y_true=y_test.values, y_pred=y_pred_test)\n",
    "        best_parameters[model_name] = clfs.best_params_\n",
    "        print(\"{0}: Tra best score: {1:.3f}:Test best score {2:.3f}\".format(model_name,tra_score[model_name],\n",
    "                                            test_score[model_name]))\n",
    "        joblib.dump(clfs.best_estimator_, '../models/{}.pkl'.format(model_name))\n",
    "        \n",
    "    return tra_score, test_score, best_parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_score, test_score, best_parameters=parameters_search(X_train, y_train, X_test, y_test,  models, parameters, df_pipeline,  score='f1', cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters[\"GB\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
